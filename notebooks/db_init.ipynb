{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db13ca32-59cf-4e1f-830e-04e6b4136fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import s3fs\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8529d165-ce3b-4988-9595-d22632522861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the working directory to root\n",
    "os.chdir(os.path.expanduser(\"~/work/MLOps\"))\n",
    "from src.utils.db import PostgreSQLDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "819ed111-b0da-440d-bb88-c4edaddb8e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop existing tables for a clean start (in reverse order of dependency)\n",
    "for table in ['reviews_sentiments', 'reviews_raw', 'movies']:\n",
    "    with PostgreSQLDatabase() as db:\n",
    "        if db.table_exists(table):\n",
    "            db.drop_table(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aee47b36-e5ce-4c72-be04-91075246f6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tables\n",
    "with PostgreSQLDatabase() as db:\n",
    "    db.create_table('movies', {\n",
    "        'movie_id': 'VARCHAR(10) PRIMARY KEY',\n",
    "        'title': 'VARCHAR(250)',\n",
    "        'release_date': 'DATE',\n",
    "        'nb_reviews': 'INTEGER',\n",
    "        'scrapping_timestamp': 'TIMESTAMP'})\n",
    "    \n",
    "    db.create_table('reviews_raw', {\n",
    "        'movie_id': 'VARCHAR(10) REFERENCES movies(movie_id) ON DELETE CASCADE',\n",
    "        'review_id': 'VARCHAR(10) PRIMARY KEY',\n",
    "        'author': 'VARCHAR(150)',\n",
    "        'title': 'VARCHAR(500)',\n",
    "        'text': 'TEXT',\n",
    "        'rating': 'INTEGER',\n",
    "        'date': 'DATE',\n",
    "        'upvotes': 'INTEGER',\n",
    "        'downvotes': 'INTEGER',\n",
    "        'last_update': 'TIMESTAMP',\n",
    "        'to_process': 'INTEGER'})\n",
    "\n",
    "    db.create_table('reviews_sentiments', {\n",
    "        'review_id': 'VARCHAR(10) PRIMARY KEY REFERENCES reviews_raw(review_id) ON DELETE CASCADE',\n",
    "        'story': 'INTEGER',\n",
    "        'acting': 'INTEGER',\n",
    "        'visuals': 'INTEGER',\n",
    "        'sounds': 'INTEGER',\n",
    "        'values': 'INTEGER',\n",
    "        'overall': 'INTEGER'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3464c69e-a747-480c-a7a3-ce302cff8572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get latest backup or sample data for a given table\n",
    "def extract_timestamp(file_name):\n",
    "    match = re.search(r'(\\d{8}_\\d{6})', file_name)\n",
    "    if match:\n",
    "        return datetime.strptime(match.group(1), '%Y%m%d_%H%M%S')\n",
    "    return None\n",
    "    \n",
    "def load_latest_backup(table_name):\n",
    "    # Look for a backup in S3\n",
    "    all_files = [f['name'] for f in fs.listdir(destination)]\n",
    "    backup_files = [f for f in all_files if f.startswith(f\"{destination}{table_name}\")]\n",
    "\n",
    "    if not backup_files:\n",
    "        # Look for sample data locally\n",
    "        try:\n",
    "            backup = pd.read_csv(f\"data/sample/{table_name}.csv\")\n",
    "            print(f\"[INFO] Loading sample data for {table_name}\")\n",
    "            return backup\n",
    "        except:\n",
    "            print(f\"[WARNING] No distant or local backup found for {table_name}\")\n",
    "\n",
    "    else:\n",
    "        file_path = max(backup_files, key=extract_timestamp)\n",
    "        timestamp = extract_timestamp(file_path).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        with fs.open(f's3://{file_path}', 'rb') as f:\n",
    "            backup = pd.read_parquet(f)\n",
    "        print(f\"[INFO] Loading distant backup for {table_name}: {timestamp}\")\n",
    "        return backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84c3c7a-42dd-4265-9f85-6d35e9c196ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaNs must be converted to None / NULL before being passed to postgreSQL\n",
    "for table in ['movies', 'reviews_raw', 'reviews_sentiments']:\n",
    "    backup_df = load_latest_backup(table)\n",
    "    \n",
    "    if backup_df is not None:\n",
    "        if table == 'reviews_raw':\n",
    "            # Replace NaN values with None in the rating column (not applicable to the df as whole because of str columns)\n",
    "            backup_df['rating'] = backup_df['rating'].astype('float').replace({np.nan: None})\n",
    "            # Verify no NaNs remain\n",
    "            non_none_nulls = sum(1 for x in backup_df['rating'] if pd.isna(x) and x is not None)\n",
    "            if non_none_nulls > 0:\n",
    "                print(f\"[ERROR] {non_none_nulls} NaNs found in reviews_raw, backup not restored\")\n",
    "                continue\n",
    "        \n",
    "        if table == 'reviews_sentiments':\n",
    "            # Apply replacement to all columns\n",
    "            for col in backup_df.columns:\n",
    "                backup_df[col] = backup_df[col].replace({np.nan: None})\n",
    "            # Verify no NaNs remain\n",
    "            non_none_nulls = sum(1 for row in backup_df.values.flatten() if pd.isna(row) and row is not None)\n",
    "            if non_none_nulls > 0:\n",
    "                print(f\"[ERROR] {non_none_nulls} NaNs found in reviews_sentiments, backup not restored\")\n",
    "                continue\n",
    "        \n",
    "        # Create tuples for database insertion, ensuring proper handling of None values\n",
    "        backup_data = [\n",
    "            tuple(None if pd.isna(value) else (str(value) if isinstance(value, str) else value) \n",
    "                 for value in row)\n",
    "            for row in backup_df.itertuples(index=False, name=None)\n",
    "        ]\n",
    "        \n",
    "        db.insert_data(table, backup_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945e91ce-24ee-4f56-a826-d4658dcd508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.close_connection()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
