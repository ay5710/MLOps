{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abbbec93-dc62-47e7-9793-83ca260a8151",
   "metadata": {},
   "source": [
    "Votes are rounded above 999 => need to load the review page to get exact values\n",
    "\n",
    "Setting language to English not necessary from the DataLab?\n",
    "\n",
    "Check if the number of scrapped matches the number of reviews displayed on the main page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d929bc-eb69-40f5-b1c0-6a650943953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from src.utils.db import PostgreSQLDatabase\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7318007e-b8a7-49ee-8225-78f6889b6580",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_id = '0089885'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30967249-3a6c-4e3f-90f5-4be1f204f6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Selenium WebDriver in headless mode\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36\")\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "print(f\"[INFO] Launching browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ad9747-bc36-4d5b-8b76-b741c040a6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load main page\n",
    "driver.get(f\"https://www.imdb.com/title/tt{movie_id}\")\n",
    "time.sleep(3)  # Allow page to load\n",
    "print(f\"[INFO] IMDb main page for movie #{movie_id} loaded\")\n",
    "\n",
    "# Consent to the collect of personal information\n",
    "accept_button = driver.find_element(By.XPATH, '//button[@data-testid=\"accept-button\"]')\n",
    "ActionChains(driver).move_to_element(accept_button).click().perform()\n",
    "time.sleep(2)\n",
    "print(f\"[INFO] Consenting to the collect of personal information\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e572a7-1bca-4bc5-a3e9-91feaf1fda83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set language to English\n",
    "language_selector = WebDriverWait(driver, 5).until(\n",
    "    EC.presence_of_element_located((By.XPATH, '//label[@for=\"nav-language-selector\"]/span'))\n",
    ")\n",
    "\n",
    "current_language = language_selector.text.strip()\n",
    "print(f\"[INFO] Current language: {current_language}\")\n",
    "\n",
    "if current_language != \"English (United States)\":\n",
    "    try:\n",
    "        driver.execute_script(\"arguments[0].click();\", language_selector)\n",
    "        language_options = WebDriverWait(driver, 5).until(\n",
    "            EC.presence_of_all_elements_located((By.XPATH, '//ul[contains(@class, \"ipc-list\")]//span'))\n",
    "        )\n",
    "        for option in language_options:\n",
    "            if \"English (United States)\" in option.text:\n",
    "                driver.execute_script(\"arguments[0].click();\", option)\n",
    "                print(\"[INFO] Language switched to English\")\n",
    "                break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to switch language to English: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeffbd5b-d7a1-487d-8407-e85a31279d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract title\n",
    "title_element = driver.find_element(By.XPATH, '//span[@data-testid=\"hero__primary-text\"]')\n",
    "movie_title = title_element.text.strip()\n",
    "print(f\"[INFO] Extracting movie title: {movie_title}\")\n",
    "\n",
    "# Extract release date\n",
    "release_date_link = driver.find_element(By.XPATH, '//li[@data-testid=\"title-details-releasedate\"]//a[@class=\"ipc-metadata-list-item__list-content-item ipc-metadata-list-item__list-content-item--link\"]')\n",
    "release_date = release_date_link.text.split(\" (\")[0].strip()\n",
    "print(f\"[INFO] Extracting release date: {release_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb144837-652c-443b-a2a7-c27ce5c7e6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load review page\n",
    "driver.get(f\"https://www.imdb.com/title/tt{movie_id}/reviews\")\n",
    "time.sleep(3)  # Allow page to load\n",
    "print(f\"[INFO] IMDb reviews page for movie #{movie_id} loaded\")\n",
    "\n",
    "# Get page source and parse with BeautifulSoup\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "# Extract the total number of reviews\n",
    "total_reviews_tag = soup.find(\"div\", attrs={\"data-testid\": \"tturv-total-reviews\"})\n",
    "if total_reviews_tag:\n",
    "    # Remove text and convert to integer\n",
    "    total_reviews_text = total_reviews_tag.get_text(strip=True).split(\" reviews\")[0]\n",
    "    total_reviews = int(total_reviews_text.replace(\",\", \"\"))\n",
    "else:\n",
    "    total_reviews = None\n",
    "\n",
    "print(f\"[INFO] Found {total_reviews} reviews to scrap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d68c452-0dc0-49ac-a33f-c01e703cdda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click the button to display all reviews\n",
    "if total_reviews > 25:\n",
    "    try:\n",
    "        # Wait for the button that specifically contains \"All\"\n",
    "        all_button = WebDriverWait(driver, 5).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '//span[contains(@class, \"ipc-see-more\")]//button[.//span[contains(text(), \"All\")]]'))\n",
    "        )\n",
    "    \n",
    "        # Click the button using JavaScript to avoid interception issues\n",
    "        driver.execute_script(\"arguments[0].click();\", all_button)\n",
    "        print(f\"[INFO] Clicking the button to display all reviews\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[WARNING] Button for displaying the reviews not found or not clickable: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42052a24-05d1-4e86-8a4c-9bec4e0d28a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click all the spoiler buttons until all reviews are displayed entirely\n",
    "spoiler_buttons = driver.find_elements(By.CLASS_NAME, \"review-spoiler-button\")\n",
    "print(f\"[INFO] Found {len(spoiler_buttons)} spoiler buttons to click\")\n",
    "    \n",
    "for i, spoiler_button in enumerate(tqdm.tqdm(spoiler_buttons, desc=\"Clicking Spoilers\", unit=\"button\")):\n",
    "    try:\n",
    "        ActionChains(driver).move_to_element(spoiler_button).click().perform()\n",
    "        time.sleep(1)  # Add a small delay to ensure clicks register properly\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Could not click spoiler button {i+1}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4d3e8f-e61c-42d9-bd57-9e8e8fbc1795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract reviews\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "data = []\n",
    "\n",
    "# Find all review articles\n",
    "reviews = soup.find_all(\"article\", class_=\"user-review-item\")\n",
    "\n",
    "# Loop through each review and extract information\n",
    "for review in reviews:\n",
    "    # 1. Extract the review identifier (integer between /rw and /?)\n",
    "    permalink_tag = review.find(\"a\", class_=\"ipc-link ipc-link--base\", attrs={\"data-testid\": \"permalink-link\"})\n",
    "    if permalink_tag:\n",
    "        identifier_match = re.search(r\"/rw(\\d+)\", permalink_tag[\"href\"])\n",
    "        if identifier_match:\n",
    "            review_id = identifier_match.group(1)\n",
    "        else:\n",
    "            review_id = None\n",
    "    else:\n",
    "        review_id = None\n",
    "\n",
    "    # 2. Extract the review date (from <li> tag with class 'review-date')\n",
    "    date_tag = review.find(\"li\", class_=\"ipc-inline-list__item review-date\")\n",
    "    review_date = date_tag.get_text(strip=True) if date_tag else None\n",
    "\n",
    "    # 3. Extract the review author (from <a> tag with class 'author-link')\n",
    "    author_tag = review.find(\"a\", class_=\"ipc-link ipc-link--base\", attrs={\"data-testid\": \"author-link\"})\n",
    "    author_name = author_tag.get_text(strip=True) if author_tag else None\n",
    "\n",
    "    # 4. Extract the upvotes and downvotes (from ipc-voting__label__count classes)\n",
    "    upvotes_tag = review.find(\"span\", class_=\"ipc-voting__label__count--up\")\n",
    "    downvotes_tag = review.find(\"span\", class_=\"ipc-voting__label__count--down\")\n",
    "    upvotes = upvotes_tag.get_text(strip=True) if upvotes_tag else 0\n",
    "    downvotes = downvotes_tag.get_text(strip=True) if downvotes_tag else 0\n",
    "\n",
    "    # 5. Extract the review text\n",
    "    spoiler_content_tag = review.find(\"div\", {\"data-testid\": \"review-spoiler-content\"})\n",
    "    \n",
    "    if spoiler_content_tag:\n",
    "        # If the spoiler content exists, extract the inner HTML of the review\n",
    "        review_text = spoiler_content_tag.find(\"div\", class_=\"ipc-html-content-inner-div\")\n",
    "        review_text = review_text.get_text(separator=\"\\n\", strip=True) if review_text else None\n",
    "    else:\n",
    "        # If no spoiler content, extract the regular review text\n",
    "        review_text_tag = review.find(\"div\", class_=\"ipc-overflowText--children\")\n",
    "        review_text = review_text_tag.get_text(separator=\"\\n\", strip=True) if review_text_tag else None\n",
    "\n",
    "    # 6. Extract the review title (from <h3> inside a <div> with class 'ipc-title')\n",
    "    title_tag = review.find(\"div\", class_=\"ipc-title\").find(\"h3\", class_=\"ipc-title__text\")\n",
    "    review_title = title_tag.get_text(strip=True) if title_tag else None\n",
    "\n",
    "    # 7. Extract the rating (from <span> with class 'ipc-rating-star--maxRating')\n",
    "    rating_tag = review.find(\"span\", class_=\"ipc-rating-star--maxRating\")\n",
    "    rating = rating_tag.previous_sibling.get_text(strip=True) if rating_tag else None\n",
    "\n",
    "    # 8. Append data to the list\n",
    "    data.append({\n",
    "        \"movie_id\": movie_id,\n",
    "        \"review_id\": review_id,\n",
    "        \"author\": author_name, \n",
    "        \"title\": review_title,\n",
    "        \"text\": review_text,\n",
    "        \"rating\": rating,\n",
    "        \"date\": review_date,\n",
    "        \"upvotes\": upvotes, \n",
    "        \"downvotes\": downvotes, \n",
    "        \"scrapping_timestamp\": datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    })\n",
    "\n",
    "# Create a dataframe from the collected data\n",
    "reviews_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0469bc5-3f0f-4fdc-be39-9f577278dc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712fed7f-69fd-4458-8b28-c6bae0e0de78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_int(value):\n",
    "    if value is None:\n",
    "        return 0\n",
    "    if 'K' in value:\n",
    "        return int(float(value.replace('K', '')) * 1000)\n",
    "    try:\n",
    "        return int(value)\n",
    "    except ValueError:\n",
    "        return 0\n",
    "\n",
    "reviews_df['upvotes'] = reviews_df['upvotes'].apply(convert_to_int)\n",
    "reviews_df['downvotes'] = reviews_df['downvotes'].apply(convert_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74b2b5b-862d-451a-8f98-7cc0a883fa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_list = reviews_df.apply(lambda row: (\n",
    "    row['movie_id'], row['review_id'], \n",
    "    f\"{row['author']}\", f\"{row['title']}\", \n",
    "    f'''{row['text']}''', row['rating'], \n",
    "    f\"{row['date']}\", row['upvotes'], row['downvotes'], \n",
    "    f\"{row['scrapping_timestamp']}\"\n",
    "), axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d58be5-4bb5-48a5-9ac8-ae406c5a0e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "db = PostgreSQLDatabase()\n",
    "db.connect()\n",
    "db.insert_data('movies', [(movie_id, movie_title, release_date, timestamp),])\n",
    "db.insert_data('reviews_raw', reviews_list)\n",
    "db.close_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469e36f0-d127-495f-b3a0-4ea8efc5a729",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
