{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ebacec-5471-4a4d-8ab1-d1494a2652c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import tqdm\n",
    "\n",
    "from datetime import datetime\n",
    "from src.analysis import GPT\n",
    "from src.scrapping import IMDb\n",
    "from src.utils.db import PostgreSQLDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cce490-f876-4214-ae08-24c1f6b0f6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_id = '0219822'  # Human nature\n",
    "# movie_id = '0089885'  # Re-animator\n",
    "# movie_id = '0101414'. # Beauty and the Best\n",
    "# movie_id = '0029583'  # Snow White (1937)\n",
    "# movie_id = '6208148'  # Snow White (2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e5fe95-e1b9-418d-ba42-624f0d538de4",
   "metadata": {},
   "source": [
    "# Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c424daa-9758-44c9-9a0a-88c17cfa0ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapper = IMDb()\n",
    "movie_scrap_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "movie_title, release_date = scrapper.get_movie(movie_id)\n",
    "total_reviews = scrapper.get_number_of_reviews(movie_id)\n",
    "reviews_df = scrapper.get_reviews(movie_id, total_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d81236a-eb46-4574-8907-f81ce5dc417e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the text hidden behind spoiler markup\n",
    "empty_reviews = reviews_df[pd.isnull(reviews_df[\"text\"]) | (reviews_df[\"text\"].str.strip() == \"\")]\n",
    "\n",
    "if len(empty_reviews) > 0:\n",
    "    print(f\"[WARNING] Missing text for {len(empty_reviews)} reviews\")\n",
    "    print(f\"[INFO] Getting text behind spoiler markups\")\n",
    "    \n",
    "    for index, row in tqdm.tqdm(empty_reviews.iterrows(), total=len(empty_reviews), desc=\"Processing empty reviews\"):\n",
    "        review_id = row[\"review_id\"]\n",
    "        spoiler_text = scrapper.get_spoiler(review_id)  # Call the function to get the spoiler\n",
    "        reviews_df.at[index, \"text\"] = spoiler_text  # Replace 'text' with the spoiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e49be52-e0db-407f-b3c1-d77d291e5e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check again for empty reviews\n",
    "empty_reviews = reviews_df[reviews_df[\"text\"].isna() | reviews_df[\"text\"].str.strip().eq(\"\") |\n",
    "                           reviews_df[\"title\"].isna() | reviews_df[\"title\"].str.strip().eq(\"\")].shape[0]\n",
    "\n",
    "if empty_reviews > 0:\n",
    "    print(f\"[WARNING] Still missing text or title for {empty_reviews} reviews\")\n",
    "else:\n",
    "    print(f\"[INFO] No reviews missing text or title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202c7a70-6dc8-4c28-b67f-44c841ac9ac9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get exact vote counts for values >999\n",
    "mask = reviews_df['upvotes'].astype(str).str.endswith('K') | reviews_df['downvotes'].astype(str).str.endswith('K')\n",
    "print(f\"[INFO] Found {len(reviews_df[mask])} reviews with rounded votes\")\n",
    "\n",
    "for index, row in reviews_df[mask].iterrows():\n",
    "    review_id = row['review_id']\n",
    "    exact_upvotes, exact_downvotes = scrapper.get_votes(review_id)\n",
    "    reviews_df.loc[index, 'upvotes'] = exact_upvotes\n",
    "    reviews_df.loc[index, 'downvotes'] = exact_downvotes\n",
    "\n",
    "reviews_df['upvotes'] = reviews_df['upvotes'].astype(int)\n",
    "reviews_df['downvotes'] = reviews_df['downvotes'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50561f0a-a60a-4e7e-86e3-28637efa6b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapper.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c153d059-b8ca-4f32-86c0-3bd0cc90ecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = PostgreSQLDatabase()\n",
    "db.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ab1709-89b3-4b45-9786-b041e85fc56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update table for movies (data must be passed as a list of tuples)\n",
    "movie_data = [(movie_id, movie_title, release_date, total_reviews, movie_scrap_time)]\n",
    "db.upsert_movie_data(movie_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8272266-5269-42bc-9a96-261f8bafbfd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Update table for reviews\n",
    "# Create a variable to identify reviews needing sentiment analysis\n",
    "reviews_df['to_process'] = 1\n",
    "\n",
    "# Convert data to a list of tuples\n",
    "reviews_list = reviews_df.apply(lambda row: (\n",
    "    str(row['movie_id']), str(row['review_id']), \n",
    "    str(row['author']), str(row['title']), \n",
    "    str(row['text']), row['rating'],\n",
    "    str(row['date']), row['upvotes'],  \n",
    "    row['downvotes'], row['last_update'], row['to_process']  \n",
    "), axis=1).tolist()\n",
    "\n",
    "# Replace NaN with None to avoid errors with postgreSQL\n",
    "reviews_list = [tuple(None if pd.isna(x) else x for x in row) for row in reviews_list]\n",
    "\n",
    "# Upserting\n",
    "db.upsert_review_data(reviews_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1904452-71f1-43ab-b999-351bdbeb670b",
   "metadata": {},
   "source": [
    "# Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569774ed-f1d6-428b-916d-9f4bb953ea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_to_process = db.query_data('reviews_raw', condition=f'to_process = 1')\n",
    "print(f\"[INFO] Found {len(reviews_to_process)} reviews to analyze for {len(pd.DataFrame(reviews_to_process)[0].unique())} movies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0521adc4-49f1-4256-9fc8-2b17a87844d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analyzer = GPT()\n",
    "for review in tqdm.tqdm(reviews_to_process, desc=\"Analyzing reviews sentiment\", unit=\"review\"):\n",
    "    review_id = review[1]\n",
    "    GPT_results = analyzer.sentiment(review)\n",
    "    data = [(review_id, *GPT_results)]\n",
    "    db.update_sentiment_data(data)\n",
    "    db.reset_indicator(review_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b09a4be-9ad3-4d68-a04b-a198d279dc4b",
   "metadata": {},
   "source": [
    "# Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5ade21-d6ac-4f4a-ac9e-62d9d8ac9f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_ENDPOINT_URL = 'https://' + os.environ['AWS_S3_ENDPOINT']\n",
    "fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': S3_ENDPOINT_URL})\n",
    "\n",
    "bucket_name = 'maeldieudonne'\n",
    "destination = bucket_name + '/diffusion/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7d97d3-a3b3-41ca-aadd-a306dbee2138",
   "metadata": {},
   "outputs": [],
   "source": [
    "for table in ['movies', 'reviews_raw', 'reviews_sentiments']:\n",
    "    db.backup_table(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a534e0-cfea-44c7-8e86-e18da9078202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_local_backup(table_name):\n",
    "    backup_files = [f for f in os.listdir(\"data/backups\") if f.startswith(table_name)]\n",
    "    \n",
    "    if not backup_files:\n",
    "        print(f\"[INFO] No local backup found for {table_name}\")\n",
    "        return None\n",
    "\n",
    "    else:\n",
    "        latest_backup = max(backup_files, key=lambda f: os.path.getctime(os.path.join(\"data/backups\", f)))\n",
    "        file_path = os.path.join(\"data/backups\", latest_backup)\n",
    "        return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6557793c-002d-4f27-9d17-43dc77fd2ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for table in ['movies', 'reviews_raw', 'reviews_sentiments']:   \n",
    "    file_path = get_latest_local_backup(table)\n",
    "        \n",
    "    if file_path is not None:\n",
    "        try:\n",
    "            fs.put(file_path, destination, content_type=\"parquet\", encoding=\"utf-8\")\n",
    "            os.remove(file_path)\n",
    "            print(f\"[INFO] Successfully uploaded {file_path} to {destination}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed uploading {file_path} to {destination}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa18b597-e042-4162-b76d-8f73adee33cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.close_connection()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
