{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86775be1-7f35-44ca-bd35-023937506191",
   "metadata": {},
   "source": [
    "***Restore is broken 'cause the structure of the table have changed.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db13ca32-59cf-4e1f-830e-04e6b4136fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import s3fs\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8529d165-ce3b-4988-9595-d22632522861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the working directory to work from install/ directory\n",
    "os.chdir(os.path.expanduser(\"~/work/MLOps\"))\n",
    "from src.utils.db import PostgreSQLDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce355bb0-cca6-4f60-b38d-53be6bb00b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to database\n",
    "db = PostgreSQLDatabase()\n",
    "db.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea96c61-b7eb-4a4c-a3cf-2bc9901e07d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to S3\n",
    "S3_ENDPOINT_URL = 'https://' + os.environ['AWS_S3_ENDPOINT']\n",
    "fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': S3_ENDPOINT_URL})\n",
    "\n",
    "bucket_name = 'maeldieudonne'\n",
    "destination = bucket_name + '/diffusion/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819ed111-b0da-440d-bb88-c4edaddb8e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop existing tables for a clean start (in reverse order of dependency)\n",
    "for table in ['reviews_sentiments', 'reviews_raw', 'movies']:\n",
    "    if db.table_exists(table):\n",
    "        db.drop_table(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee47b36-e5ce-4c72-be04-91075246f6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tables\n",
    "db.create_table('movies', {\n",
    "    'movie_id': 'INTEGER PRIMARY KEY',\n",
    "    'title': 'VARCHAR(250)',\n",
    "    'release_date': 'DATE',\n",
    "    'scrapping_timestamp': 'TIMESTAMP'\n",
    "})\n",
    "    \n",
    "db.create_table('reviews_raw', {\n",
    "    'movie_id': 'INTEGER REFERENCES movies(movie_id) ON DELETE CASCADE',\n",
    "    'review_id': 'INTEGER PRIMARY KEY',\n",
    "    'author': 'VARCHAR(150)',\n",
    "    'title': 'VARCHAR(500)',\n",
    "    'text': 'TEXT',\n",
    "    'rating': 'INTEGER',\n",
    "    'date': 'DATE',\n",
    "    'upvotes': 'INTEGER',\n",
    "    'downvotes': 'INTEGER',\n",
    "    'scrapping_timestamp': 'TIMESTAMP'\n",
    "})\n",
    "\n",
    "db.create_table('reviews_sentiments', {\n",
    "    'review_id': 'INTEGER PRIMARY KEY REFERENCES reviews_raw(review_id) ON DELETE CASCADE',\n",
    "    'story': 'INTEGER',\n",
    "    'acting': 'INTEGER',\n",
    "    'visuals': 'INTEGER',\n",
    "    'sounds': 'INTEGER',\n",
    "    'values': 'INTEGER',\n",
    "    'overall': 'INTEGER'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3464c69e-a747-480c-a7a3-ce302cff8572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get latest backup or sample data for a given table\n",
    "def extract_timestamp(file_name):\n",
    "    match = re.search(r'(\\d{8}_\\d{6})', file_name)\n",
    "    if match:\n",
    "        return datetime.strptime(match.group(1), '%Y%m%d_%H%M%S')\n",
    "    return None\n",
    "    \n",
    "def load_latest_backup(table_name):\n",
    "    # Look for a backup in S3\n",
    "    all_files = [f['name'] for f in fs.listdir(destination)]\n",
    "    backup_files = [f for f in all_files if f.startswith(f\"{destination}{table_name}\")]\n",
    "\n",
    "    if not backup_files:\n",
    "        # Look for sample data locally\n",
    "        try:\n",
    "            backup = pd.read_csv(f\"data/sample/{table_name}.csv\")\n",
    "            print(f\"Loading sample data for {table_name}\")\n",
    "            return backup\n",
    "        except:\n",
    "            print(f\"No distant or local backup found for {table_name}\")\n",
    "\n",
    "    else:\n",
    "        file_path = max(backup_files, key=extract_timestamp)\n",
    "        timestamp = extract_timestamp(file_path).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        with fs.open(f's3://{file_path}', 'rb') as f:\n",
    "            backup = pd.read_parquet(f)\n",
    "        print(f\"Loading distant backup for {table_name}: {timestamp}\")\n",
    "        return backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b623640-62be-456c-8548-43414092e342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load backups or samples\n",
    "for table in ['movies', 'reviews_raw', 'reviews_sentiments']:\n",
    "    backup_df = load_latest_backup(table)\n",
    "    # backup_df = backup_df.where(pd.notna(backup_df), None)\n",
    "    if backup_df is not None:\n",
    "        backup_data = [\n",
    "            tuple(str(value) if isinstance(value, str) else value for value in row)\n",
    "            for row in backup_df.itertuples(index=False, name=None)\n",
    "        ]\n",
    "        db.insert_data(table, backup_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945e91ce-24ee-4f56-a826-d4658dcd508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.close_connection()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
